{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:27:06.837273Z",
     "start_time": "2023-08-01T14:27:05.812282Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "['AlexNet',\n 'AlexNet_Weights',\n 'ConvNeXt',\n 'ConvNeXt_Base_Weights',\n 'ConvNeXt_Large_Weights',\n 'ConvNeXt_Small_Weights',\n 'ConvNeXt_Tiny_Weights',\n 'DenseNet',\n 'DenseNet121_Weights',\n 'DenseNet161_Weights',\n 'DenseNet169_Weights',\n 'DenseNet201_Weights',\n 'EfficientNet',\n 'EfficientNet_B0_Weights',\n 'EfficientNet_B1_Weights',\n 'EfficientNet_B2_Weights',\n 'EfficientNet_B3_Weights',\n 'EfficientNet_B4_Weights',\n 'EfficientNet_B5_Weights',\n 'EfficientNet_B6_Weights',\n 'EfficientNet_B7_Weights',\n 'EfficientNet_V2_L_Weights',\n 'EfficientNet_V2_M_Weights',\n 'EfficientNet_V2_S_Weights',\n 'GoogLeNet',\n 'GoogLeNetOutputs',\n 'GoogLeNet_Weights',\n 'Inception3',\n 'InceptionOutputs',\n 'Inception_V3_Weights',\n 'MNASNet',\n 'MNASNet0_5_Weights',\n 'MNASNet0_75_Weights',\n 'MNASNet1_0_Weights',\n 'MNASNet1_3_Weights',\n 'MaxVit',\n 'MaxVit_T_Weights',\n 'MobileNetV2',\n 'MobileNetV3',\n 'MobileNet_V2_Weights',\n 'MobileNet_V3_Large_Weights',\n 'MobileNet_V3_Small_Weights',\n 'RegNet',\n 'RegNet_X_16GF_Weights',\n 'RegNet_X_1_6GF_Weights',\n 'RegNet_X_32GF_Weights',\n 'RegNet_X_3_2GF_Weights',\n 'RegNet_X_400MF_Weights',\n 'RegNet_X_800MF_Weights',\n 'RegNet_X_8GF_Weights',\n 'RegNet_Y_128GF_Weights',\n 'RegNet_Y_16GF_Weights',\n 'RegNet_Y_1_6GF_Weights',\n 'RegNet_Y_32GF_Weights',\n 'RegNet_Y_3_2GF_Weights',\n 'RegNet_Y_400MF_Weights',\n 'RegNet_Y_800MF_Weights',\n 'RegNet_Y_8GF_Weights',\n 'ResNeXt101_32X8D_Weights',\n 'ResNeXt101_64X4D_Weights',\n 'ResNeXt50_32X4D_Weights',\n 'ResNet',\n 'ResNet101_Weights',\n 'ResNet152_Weights',\n 'ResNet18_Weights',\n 'ResNet34_Weights',\n 'ResNet50_Weights',\n 'ShuffleNetV2',\n 'ShuffleNet_V2_X0_5_Weights',\n 'ShuffleNet_V2_X1_0_Weights',\n 'ShuffleNet_V2_X1_5_Weights',\n 'ShuffleNet_V2_X2_0_Weights',\n 'SqueezeNet',\n 'SqueezeNet1_0_Weights',\n 'SqueezeNet1_1_Weights',\n 'SwinTransformer',\n 'Swin_B_Weights',\n 'Swin_S_Weights',\n 'Swin_T_Weights',\n 'Swin_V2_B_Weights',\n 'Swin_V2_S_Weights',\n 'Swin_V2_T_Weights',\n 'VGG',\n 'VGG11_BN_Weights',\n 'VGG11_Weights',\n 'VGG13_BN_Weights',\n 'VGG13_Weights',\n 'VGG16_BN_Weights',\n 'VGG16_Weights',\n 'VGG19_BN_Weights',\n 'VGG19_Weights',\n 'ViT_B_16_Weights',\n 'ViT_B_32_Weights',\n 'ViT_H_14_Weights',\n 'ViT_L_16_Weights',\n 'ViT_L_32_Weights',\n 'VisionTransformer',\n 'Weights',\n 'WeightsEnum',\n 'Wide_ResNet101_2_Weights',\n 'Wide_ResNet50_2_Weights',\n '_GoogLeNetOutputs',\n '_InceptionOutputs',\n '__builtins__',\n '__cached__',\n '__doc__',\n '__file__',\n '__loader__',\n '__name__',\n '__package__',\n '__path__',\n '__spec__',\n '_api',\n '_meta',\n '_utils',\n 'alexnet',\n 'convnext',\n 'convnext_base',\n 'convnext_large',\n 'convnext_small',\n 'convnext_tiny',\n 'densenet',\n 'densenet121',\n 'densenet161',\n 'densenet169',\n 'densenet201',\n 'detection',\n 'efficientnet',\n 'efficientnet_b0',\n 'efficientnet_b1',\n 'efficientnet_b2',\n 'efficientnet_b3',\n 'efficientnet_b4',\n 'efficientnet_b5',\n 'efficientnet_b6',\n 'efficientnet_b7',\n 'efficientnet_v2_l',\n 'efficientnet_v2_m',\n 'efficientnet_v2_s',\n 'get_model',\n 'get_model_builder',\n 'get_model_weights',\n 'get_weight',\n 'googlenet',\n 'inception',\n 'inception_v3',\n 'list_models',\n 'maxvit',\n 'maxvit_t',\n 'mnasnet',\n 'mnasnet0_5',\n 'mnasnet0_75',\n 'mnasnet1_0',\n 'mnasnet1_3',\n 'mobilenet',\n 'mobilenet_v2',\n 'mobilenet_v3_large',\n 'mobilenet_v3_small',\n 'mobilenetv2',\n 'mobilenetv3',\n 'optical_flow',\n 'quantization',\n 'regnet',\n 'regnet_x_16gf',\n 'regnet_x_1_6gf',\n 'regnet_x_32gf',\n 'regnet_x_3_2gf',\n 'regnet_x_400mf',\n 'regnet_x_800mf',\n 'regnet_x_8gf',\n 'regnet_y_128gf',\n 'regnet_y_16gf',\n 'regnet_y_1_6gf',\n 'regnet_y_32gf',\n 'regnet_y_3_2gf',\n 'regnet_y_400mf',\n 'regnet_y_800mf',\n 'regnet_y_8gf',\n 'resnet',\n 'resnet101',\n 'resnet152',\n 'resnet18',\n 'resnet34',\n 'resnet50',\n 'resnext101_32x8d',\n 'resnext101_64x4d',\n 'resnext50_32x4d',\n 'segmentation',\n 'shufflenet_v2_x0_5',\n 'shufflenet_v2_x1_0',\n 'shufflenet_v2_x1_5',\n 'shufflenet_v2_x2_0',\n 'shufflenetv2',\n 'squeezenet',\n 'squeezenet1_0',\n 'squeezenet1_1',\n 'swin_b',\n 'swin_s',\n 'swin_t',\n 'swin_transformer',\n 'swin_v2_b',\n 'swin_v2_s',\n 'swin_v2_t',\n 'vgg',\n 'vgg11',\n 'vgg11_bn',\n 'vgg13',\n 'vgg13_bn',\n 'vgg16',\n 'vgg16_bn',\n 'vgg19',\n 'vgg19_bn',\n 'video',\n 'vision_transformer',\n 'vit_b_16',\n 'vit_b_32',\n 'vit_h_14',\n 'vit_l_16',\n 'vit_l_32',\n 'wide_resnet101_2',\n 'wide_resnet50_2']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(models)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:27:08.674797Z",
     "start_time": "2023-08-01T14:27:08.654371Z"
    }
   },
   "id": "a8114047de9a0775"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "alexnet = models.AlexNet()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:28:19.125357Z",
     "start_time": "2023-08-01T14:28:18.937258Z"
    }
   },
   "id": "8b169055b119b5eb"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "AlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:28:48.284800Z",
     "start_time": "2023-08-01T14:28:48.277515Z"
    }
   },
   "id": "f8916ea97f28db7"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:37:17.144260Z",
     "start_time": "2023-08-01T14:37:17.133831Z"
    }
   },
   "id": "69f9829c74fd0f9b"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "zhouye = Image.open(\"/Users/zcq30/Documents/XJLTU Learning/XJTLU/FMP/Pytorch/Coconut.jpeg\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:42:13.226383Z",
     "start_time": "2023-08-01T14:42:13.218756Z"
    }
   },
   "id": "1d768f6ae3e8520e"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 256, 256])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhouye_tensor = preprocess(zhouye)\n",
    "zhouye_tensor.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:43:17.845117Z",
     "start_time": "2023-08-01T14:43:17.805884Z"
    }
   },
   "id": "ba610a3c4df48b2c"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 3, 256, 256])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "batch_Coconut_t = torch.unsqueeze(zhouye_tensor, 0)\n",
    "batch_Coconut_t.shape\n",
    "# 输出的第一个是 batch size\n",
    "# 输出的第二个是色彩空间\n",
    "# 第三四个是图片尺寸"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:45:08.523175Z",
     "start_time": "2023-08-01T14:45:08.505894Z"
    }
   },
   "id": "dc87bc2f5f8d9ec7"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /Users/zcq30/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
      "13.7%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "54.3%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "93.0%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet101(pretrained = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:53:04.005127Z",
     "start_time": "2023-08-01T14:52:53.890203Z"
    }
   },
   "id": "ea484a501d78d7ff"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (6): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (7): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (8): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (9): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (10): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (11): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (12): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (13): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (14): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (15): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (16): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (17): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (18): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (19): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (20): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (21): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (22): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:53:08.399421Z",
     "start_time": "2023-08-01T14:53:08.376839Z"
    }
   },
   "id": "a97d9871c6f34407"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (6): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (7): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (8): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (9): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (10): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (11): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (12): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (13): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (14): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (15): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (16): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (17): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (18): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (19): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (20): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (21): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (22): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:53:41.962261Z",
     "start_time": "2023-08-01T14:53:41.951424Z"
    }
   },
   "id": "13d6b80e10d88500"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-2.0031e+00, -2.4878e+00, -1.5097e+00, -2.5369e+00, -1.2904e+00,\n         -6.6389e-01, -3.3879e+00,  1.3445e-01, -2.4191e+00, -3.2824e+00,\n         -3.7210e+00, -3.0055e+00, -2.9461e+00, -1.5166e+00, -3.7423e+00,\n         -1.3599e+00, -2.7092e+00, -2.8335e+00, -3.2475e+00, -2.0792e+00,\n         -2.4517e+00, -2.4855e+00, -1.1313e+00, -1.1858e+00, -1.8257e+00,\n         -3.0860e+00, -3.6353e+00, -2.7523e+00, -3.3046e-01, -2.5428e+00,\n         -3.1154e+00, -1.2083e+00, -2.0335e+00, -1.8320e+00,  3.0399e-01,\n         -4.3038e+00, -2.5034e+00, -3.1747e+00, -1.8049e+00, -1.8316e+00,\n         -9.9470e-01, -3.2890e+00, -1.8315e+00,  4.4306e-01, -1.0646e+00,\n         -1.8933e-01, -7.8168e-01, -1.8461e+00, -1.3302e+00, -3.5984e-01,\n         -1.1855e+00,  2.8029e+00, -1.8235e+00, -3.0002e+00,  6.6698e-01,\n         -1.7764e+00, -2.6637e+00, -3.1791e+00, -3.8713e+00,  5.7823e-01,\n          1.1425e+00, -2.8402e-01, -2.3259e+00, -1.0934e+00, -1.8287e+00,\n         -2.6729e+00, -8.8933e-01, -8.3893e-02, -1.3570e+00, -1.5068e+00,\n         -3.5574e+00,  1.4633e+00, -5.2279e+00, -1.9997e+00, -4.0085e+00,\n         -3.2288e+00, -7.3244e-01, -2.9081e+00,  1.6371e-01, -6.7204e-01,\n         -4.7203e-01, -2.9152e+00, -1.3084e+00, -1.3205e+00, -3.0221e+00,\n         -2.2533e+00, -1.4609e+00, -1.1073e+00, -3.4998e-01, -3.4937e+00,\n         -3.9014e+00, -3.7818e+00, -3.4239e+00, -1.6246e+00, -3.2635e+00,\n         -4.9797e+00, -2.0742e+00, -4.0138e+00, -3.1465e+00, -3.1003e+00,\n         -3.2566e+00, -1.8244e+00, -3.3693e+00, -2.1189e+00,  1.0977e-01,\n         -3.3570e+00,  6.7613e-01, -2.4321e-01, -1.9240e+00, -4.3135e+00,\n         -2.8836e+00, -2.8410e+00, -3.4342e-01, -1.3015e+00, -1.7663e+00,\n         -3.9399e+00, -4.9237e+00,  9.2999e-02, -7.9869e-01, -4.3740e+00,\n         -3.8795e+00, -6.5696e-01, -8.6555e-01, -2.1691e+00, -6.9582e-01,\n         -8.3716e-01, -1.9701e+00, -2.0271e+00, -3.0478e+00, -3.2236e+00,\n         -3.0586e+00, -3.5159e+00, -2.3577e+00, -2.1456e+00, -3.4373e+00,\n         -3.8611e+00, -3.4341e+00, -3.4751e+00, -2.7842e+00, -4.7316e+00,\n         -5.2953e+00, -2.3876e+00, -4.9645e+00, -2.5699e+00, -3.3700e+00,\n         -2.3890e+00, -4.3705e+00, -2.7269e+00, -1.3200e+00, -4.0287e+00,\n         -1.7878e+00,  2.5747e+00, -2.5051e-02,  1.6843e+00,  6.8942e-02,\n          1.0411e-02,  9.4037e-01,  5.5003e-01,  3.7733e-01,  1.1459e+00,\n          6.7742e-01,  8.4223e-01, -4.4912e-01,  1.1746e+00, -3.0422e-01,\n          1.1538e+00, -1.6936e+00, -3.1700e+00,  2.1690e+00,  1.4175e+00,\n         -1.0949e+00,  2.4639e+00,  1.7085e+00,  4.9664e-01,  6.3071e-02,\n         -1.4509e+00, -8.6283e-01,  7.9261e-01,  2.3336e+00,  6.9284e-01,\n         -2.7019e-01, -1.0145e+00,  2.0955e-01, -7.8256e-01,  7.7922e-01,\n         -6.2589e-01,  1.2962e+00,  3.1253e+00, -3.4186e+00,  6.5097e-01,\n         -1.9394e+00,  3.0720e-01, -1.2407e+00, -1.8103e-01, -2.7308e+00,\n          2.5781e+00, -7.5815e-02, -1.5729e+00, -1.1287e+00, -3.7761e-01,\n         -3.5969e-01,  2.0211e+00,  3.5638e-01,  2.1927e+00,  2.5530e+00,\n         -3.3635e+00, -2.7681e+00, -1.0144e-01,  1.9324e-01,  2.1734e-01,\n         -1.3545e+00,  1.7453e+00, -2.8003e-01,  1.0121e+00, -2.1492e-01,\n         -8.5047e-01, -4.0738e-02, -1.1104e+00, -1.2848e+00,  2.3123e-01,\n          8.5471e-01, -1.0022e+00, -7.8011e-01,  7.6953e-01,  1.7375e-02,\n          5.0641e-01,  7.3663e-01, -3.3859e-01,  5.9063e-01, -6.5874e-01,\n          1.7061e+00, -1.1961e+00, -4.5046e-01, -8.6864e-01, -1.1904e-01,\n          4.4718e-01,  2.3595e+00,  6.9184e-01, -2.4930e-01, -2.8690e-01,\n         -6.4962e-01, -1.4736e+00,  8.9703e-01,  9.3733e-01, -2.0034e+00,\n          1.5151e+00,  7.8990e-01, -1.7077e-01,  1.8895e+00,  1.6278e+00,\n          2.6888e+00,  1.5659e+00, -7.3318e-01, -8.5353e-02,  1.6447e+00,\n         -1.0451e+00, -1.1929e+00,  2.0976e-01,  5.4630e-01,  1.1135e+00,\n         -1.0522e+00, -3.5603e-01, -4.9565e-01,  2.2130e+00,  1.1061e+00,\n          1.0157e+00, -8.5721e-01, -1.0170e+00, -3.2011e-01, -7.0579e-01,\n         -8.9072e-02,  1.3039e+00,  9.9376e-01,  1.0917e+00, -1.1881e+00,\n         -1.8265e+00, -3.0738e-01,  1.4351e-01, -1.3538e+00, -5.9681e-01,\n          7.1391e-01,  3.1910e+00,  2.3032e+00,  1.7652e+00,  1.7015e+00,\n          4.6882e+00,  5.8175e-01,  1.0901e+00, -6.9396e-01, -1.9530e+00,\n         -1.2040e+00,  6.0100e-01,  3.4280e-02, -6.2568e-01, -1.6346e+00,\n         -2.9762e+00, -9.0934e-01, -3.0238e+00, -1.4747e+00,  2.9833e-01,\n         -4.4450e+00, -2.2266e+00, -4.6168e+00, -3.9384e+00, -3.9059e+00,\n         -2.9295e+00, -2.1065e+00, -2.5644e+00, -3.1003e+00, -2.8765e+00,\n         -2.4128e+00, -1.5275e+00, -1.9710e+00, -1.4867e+00, -1.5497e-01,\n         -1.0527e+00, -4.2646e+00, -3.2734e+00, -2.4459e+00, -2.4110e+00,\n         -3.8119e+00, -2.9729e+00, -3.0225e+00, -4.4912e+00, -2.1577e+00,\n         -1.4201e+00, -2.0756e+00, -4.7570e-01, -2.5486e+00, -4.1459e+00,\n          1.5426e-01, -2.8669e-01, -9.9505e-01, -1.5849e+00, -2.0574e+00,\n         -1.8592e+00, -2.9512e+00, -2.0841e+00, -8.1888e-02, -1.2141e+00,\n         -1.2000e+00, -2.7193e+00, -3.6437e+00, -2.2287e+00, -1.5489e+00,\n         -1.0066e+00, -1.7809e+00, -2.8186e+00, -3.1576e+00, -2.1284e+00,\n         -1.1391e+00, -1.4442e+00, -1.0968e+00, -1.2756e+00,  2.8583e-01,\n         -1.3018e+00,  5.9898e-01, -2.0671e+00,  1.2399e+00,  2.4350e-01,\n         -1.6801e+00, -1.2327e-01, -2.6267e-02,  2.2904e-01, -1.3131e+00,\n         -1.0297e+00, -2.2449e+00, -1.0347e+00, -3.0081e+00, -3.4027e+00,\n         -2.7092e+00, -2.8277e+00, -3.1032e+00, -1.7592e+00, -1.3209e+00,\n         -2.7374e+00, -4.2557e+00, -9.3336e-01, -2.4908e+00, -3.0175e+00,\n         -9.8766e-01, -1.1752e+00, -6.8294e-02, -1.0568e+00, -3.8136e+00,\n         -1.2299e+00, -3.0107e+00, -2.9163e+00, -2.5087e+00, -9.6494e-01,\n         -1.0515e+00, -1.7987e+00, -4.1170e+00, -1.6826e+00, -7.9869e-01,\n         -3.2062e+00, -3.8956e+00, -4.7222e+00,  7.3362e-01,  9.9147e+00,\n          5.1418e+00,  3.7405e+00,  3.8320e+00, -4.3332e+00, -2.3631e+00,\n         -1.6193e+00,  3.2269e+00, -2.2055e+00, -2.7048e+00,  3.5563e+00,\n         -4.4463e+00,  9.0962e-01,  1.7158e+00,  8.1098e-01,  3.3396e+00,\n          3.2605e-01,  2.9791e+00,  4.2754e+00, -4.9136e-01,  2.7816e+00,\n          2.2658e+00,  3.0693e-01,  1.8163e+00,  8.7178e-01,  5.8562e-01,\n          1.1177e+00,  1.5229e+00,  1.4462e+00,  1.0152e+00,  2.4893e+00,\n         -7.6539e-01,  2.3453e+00,  3.9237e+00,  1.7940e+00,  4.4376e+00,\n          2.4003e+00, -2.3752e+00, -4.1896e-01, -7.0855e-01,  1.2959e+00,\n          9.9734e-01,  7.7301e-02,  1.8509e+00, -4.0029e-01, -1.1931e+00,\n          1.9317e-01,  7.2803e-01,  1.1779e+00, -1.8240e+00, -1.9205e+00,\n         -4.4731e-01,  5.5476e-01,  3.1043e+00,  2.6536e+00,  1.3494e+00,\n          1.2620e+00,  3.3916e+00,  4.5893e+00, -1.0246e+00,  3.2913e+00,\n         -7.6835e-01,  1.6233e+00,  3.5540e+00,  2.2504e+00,  2.9336e+00,\n          1.2970e+00, -1.0308e+00, -1.4508e+00, -7.7222e-01,  8.6707e-01,\n          4.3004e+00, -5.1409e-01, -9.1314e-01,  4.6203e-01,  4.4053e+00,\n         -7.3801e-01, -1.4644e+00,  3.6157e-01,  3.1426e+00,  1.4360e-01,\n          1.1948e+00,  9.2854e-01, -1.7987e-01, -1.4353e+00, -4.5866e+00,\n          1.6607e+00,  2.9789e+00,  3.5061e+00,  9.6191e-02, -1.0175e-01,\n          1.3148e+00,  2.1216e+00,  1.6606e+00,  5.2600e-01,  7.8449e-01,\n          2.3578e-01,  3.1854e+00,  4.7305e-01,  3.8405e+00,  1.8963e+00,\n         -1.2138e+00,  1.1758e+01,  2.2847e+00,  1.4222e+00,  6.4613e-01,\n         -1.1396e+00,  1.7024e+00,  8.0763e-01,  1.2330e+00, -3.4564e-01,\n         -1.2349e+00, -2.4667e+00,  3.0262e+00,  2.8291e+00,  1.3031e+00,\n          4.3237e+00,  3.7456e+00, -1.3101e-01,  2.8034e+00,  2.7617e+00,\n          2.5271e+00, -1.2934e-01,  6.0469e-01,  4.7796e+00,  9.9317e-02,\n         -1.3345e+00,  1.6745e+00,  1.6073e+00,  1.9388e+00,  1.6238e+00,\n          3.0150e+00,  1.9011e+00, -1.5032e-01, -1.3789e+00,  7.2699e-01,\n         -2.6220e+00, -3.7494e+00, -1.2569e+00, -9.4762e-01,  2.1974e+00,\n         -1.5020e+00,  3.1585e+00,  5.9344e+00,  3.2551e+00, -2.6415e+00,\n          2.2024e+00,  4.8094e+00, -4.3691e+00,  4.6746e-01,  8.2316e-01,\n         -2.1016e+00,  4.0595e-01,  3.7007e+00,  3.1150e-03, -2.0763e+00,\n         -2.5097e+00,  2.2679e+00,  1.4171e+00,  3.8181e+00,  1.8479e+00,\n          1.5597e+00, -9.9795e-01,  2.6072e-01, -1.3216e-01,  4.0813e+00,\n         -6.3641e-01,  2.6109e+00, -2.4544e-01,  6.1401e+00, -3.5921e+00,\n          3.3665e+00, -1.9454e+00,  7.9565e-01, -4.3536e-02,  1.3272e+00,\n         -3.6832e+00, -3.3594e+00,  3.5355e+00,  7.7356e+00,  5.7715e+00,\n         -7.6295e-01, -2.3124e+00, -1.2323e+00,  1.7432e+00,  1.8302e+00,\n          4.0905e+00, -3.1236e+00,  3.0126e+00,  2.3812e+00,  4.3767e+00,\n          1.7573e-01,  1.2426e+00, -2.4882e+00,  4.2675e+00,  4.1232e+00,\n         -4.1367e+00,  2.6592e+00,  3.4204e-01,  6.0731e+00, -3.3688e+00,\n          5.5710e-01,  4.7616e+00,  2.8674e+00, -2.3871e+00,  2.8551e+00,\n          7.7035e-01,  5.7875e+00,  5.3028e+00,  5.8612e+00, -3.2163e+00,\n          4.2216e+00,  1.3746e+00,  2.2740e-01, -1.6006e-01,  5.5384e+00,\n          2.2638e+00,  4.5807e-01,  1.9497e+00, -1.9392e-01,  4.5667e+00,\n          4.8523e+00, -5.5515e-01,  1.6808e+00,  2.9525e-01, -3.4150e-01,\n         -5.1891e+00,  4.1666e+00, -1.5967e+00, -2.7227e+00,  3.6576e+00,\n          2.7728e+00,  7.7962e-01,  1.9033e+00,  1.4050e+00, -5.4598e-01,\n         -3.9751e-01,  2.5974e+00,  1.7118e+00,  3.9963e+00,  1.5441e+00,\n         -2.6433e+00,  3.3369e+00,  3.1190e+00,  3.8248e+00,  4.9846e+00,\n         -1.4846e+00,  4.7323e-01, -5.3307e-01,  5.3452e-01,  4.1101e-01,\n          4.6060e+00, -9.2452e-02,  3.2782e+00, -1.1366e+00, -3.1673e+00,\n          3.3133e+00, -2.6092e+00, -8.5050e-01,  1.6555e+00, -2.7681e-01,\n         -8.4450e-01, -3.5667e+00, -9.7952e-01,  1.6614e-01,  3.0800e+00,\n         -2.9924e-01, -1.0026e-01,  4.6505e+00,  1.3339e+00,  5.7090e+00,\n         -5.0808e-01,  7.8551e-01,  2.1829e+00,  1.4136e+00,  6.5782e-01,\n         -1.4634e+00, -6.3015e-01,  1.0336e+00,  2.6528e+00, -4.8299e-01,\n          1.6824e+00,  5.3979e+00, -5.6380e-01,  3.6763e+00,  2.0260e-01,\n         -2.8411e+00, -3.8383e+00,  2.1858e+00,  9.4220e-01,  5.2708e+00,\n         -3.6061e+00,  1.7520e+00, -8.6728e-01, -5.6558e-01, -3.7642e+00,\n         -3.8861e-01,  3.0772e+00,  7.9067e+00,  4.5851e-01,  2.7385e+00,\n          3.0549e-02,  2.2990e-01,  1.4246e+00,  1.2378e+00,  7.0059e-01,\n         -3.5717e+00, -1.4079e+00,  3.7635e-02,  4.2915e-01,  1.5894e+00,\n          1.7835e+00,  3.3665e+00, -2.0540e+00,  1.3489e+00,  3.4350e+00,\n          3.4588e-01,  1.0098e+00, -2.9512e+00, -1.0297e-01,  2.5646e+00,\n          3.0837e+00,  2.5855e+00,  3.7382e+00,  1.8900e-05, -1.2424e+00,\n          7.7444e-01, -2.2999e+00, -4.1238e-02,  1.5756e+00, -1.0368e+00,\n         -2.5264e+00,  3.5119e+00,  6.0517e-01,  2.9161e+00, -4.6328e+00,\n          5.6111e+00,  4.6139e+00,  1.0076e+00, -2.0222e+00, -3.2152e-02,\n          3.0007e+00,  5.8280e+00,  8.2060e-02,  2.3921e+00, -1.0045e+00,\n          5.9801e+00,  1.2371e-01,  2.4840e+00,  7.8346e-01,  2.4203e+00,\n          6.0295e+00, -5.4578e-01,  2.6107e+00,  4.6120e+00,  6.7856e-01,\n         -4.6304e-01, -2.2175e+00, -1.6261e+00,  2.7413e-01,  2.2315e+00,\n          1.7595e+00,  5.4293e+00,  1.3302e+00,  2.7851e+00,  2.6623e+00,\n          3.4031e+00, -1.8302e+00,  1.8417e+00, -1.2569e+00,  2.6481e+00,\n          2.4322e+00,  2.7219e+00,  1.8905e+00,  1.0144e+00,  1.5585e+00,\n          2.9739e+00,  3.3070e+00,  2.3869e-01,  1.3626e+00, -2.3688e+00,\n         -7.5869e-01, -7.7401e-01,  2.7245e+00,  3.3581e-01,  2.2057e+00,\n          1.5663e+00,  4.4069e-01, -5.3885e-01,  1.0102e+00,  4.5826e+00,\n         -6.4302e-01,  1.5195e+00,  2.1673e+00,  6.3622e+00,  4.6594e+00,\n          8.9052e-01,  4.4127e+00,  7.6101e+00, -7.7114e-01,  3.4165e+00,\n          8.9209e-01, -2.2978e+00, -5.2942e-01, -1.5346e+00, -9.3801e-01,\n          7.1910e-01,  3.6512e+00, -1.5736e+00,  3.4192e+00, -6.1771e-01,\n         -2.0685e+00,  4.7876e+00, -1.5748e-01,  1.9549e+00, -3.9878e+00,\n         -2.2509e+00, -1.2564e+00, -1.0956e+00,  7.5672e+00,  4.7297e+00,\n         -5.2886e+00, -3.7781e+00,  1.3373e+00,  2.9768e+00,  4.9213e+00,\n         -3.0899e+00,  1.6135e+00,  1.8454e+00,  2.9223e-01, -2.1740e+00,\n          6.5143e-01,  5.5998e+00, -9.3682e-02, -3.0789e+00,  5.7949e+00,\n         -2.4417e+00,  3.3808e+00,  5.1328e+00, -3.1323e-01, -4.4891e-01,\n          3.0589e+00,  8.1502e+00, -4.7783e-02,  4.5043e-01, -1.0943e+00,\n          4.6120e+00,  4.7539e+00, -1.3788e+00,  4.7007e-02, -7.6301e-02,\n          9.7177e-01,  5.5104e+00,  3.5464e+00, -5.2473e-01,  1.2415e+01,\n         -7.3524e-02, -4.6382e+00,  5.2741e+00, -4.9473e-01,  9.3693e-01,\n          4.6585e-01,  1.7015e+00,  4.0000e+00,  1.2722e+00, -3.8453e+00,\n         -4.9957e-01, -9.3479e-01, -3.6701e-02, -1.5270e+00,  6.4737e+00,\n          9.0072e-01, -3.6609e+00,  3.5195e+00, -3.9926e-01, -4.7874e+00,\n          1.8499e+00,  2.9294e+00,  6.5955e-01, -1.1205e+00,  1.8385e+00,\n          3.0906e+00,  2.9064e+00,  3.9197e+00, -4.2745e-01,  1.9302e+00,\n          1.0327e+01, -8.8287e-01,  3.6077e+00, -2.5335e+00,  3.0622e+00,\n          4.8172e-01, -1.9788e+00,  3.6479e+00, -1.1718e-01,  4.6653e+00,\n         -2.7343e+00,  8.5168e-01,  2.2427e+00,  2.3380e+00,  1.5058e+00,\n         -8.5753e-01, -1.4542e+00,  3.1029e-01,  6.3261e+00,  2.5418e+00,\n          6.1661e+00,  1.8444e+00,  1.7877e+00, -7.8859e-01, -6.1786e-01,\n          2.2999e+00,  5.7749e+00, -1.3774e+00, -2.3222e+00, -5.5840e+00,\n          2.1333e+00,  4.2014e+00,  1.2385e+00,  2.8887e+00, -2.0214e-01,\n         -6.2682e-01,  1.7932e+00, -3.2683e-01, -3.9793e-01, -1.5965e+00,\n         -3.0801e+00, -2.3192e+00, -1.7088e+00, -2.5044e+00,  7.6005e-02,\n         -1.5457e+00, -1.2721e+00, -1.3390e+00, -3.1895e+00, -2.7919e+00,\n         -2.6052e+00,  6.9395e-01, -1.5804e+00, -3.1189e-01, -9.6446e-01,\n         -1.1017e+00, -1.8739e+00, -2.0281e+00, -2.7426e-01, -2.3011e+00,\n         -1.9146e+00, -3.4421e+00, -1.0392e+00,  1.0926e+00, -2.3834e+00,\n         -5.2393e-01, -2.2061e-01, -3.3286e+00, -1.2787e+00,  1.7460e+00,\n         -2.0334e+00, -2.2425e+00, -4.8394e-01,  2.8397e+00, -1.4708e+00,\n         -1.1296e+00,  1.5321e+00, -2.7468e+00, -3.7836e-01, -1.9643e-01,\n          7.8590e-01,  4.2557e+00, -1.0133e+00,  2.2066e+00,  1.2398e+00,\n         -2.5091e-01,  2.3574e+00, -1.2027e+00, -4.8173e+00, -1.8364e+00,\n         -3.8129e-01, -1.9115e+00, -4.1722e-01, -8.4020e-01, -2.2815e+00,\n         -1.9721e-01,  3.1599e+00,  3.7350e+00, -1.9433e+00, -7.7734e-01,\n         -2.6245e-01, -3.4865e-01, -7.4076e-01, -2.1556e+00, -2.8777e+00,\n         -2.6155e-02, -4.7520e+00, -3.7277e+00, -5.5630e+00, -4.5791e+00,\n         -3.9885e+00, -3.9942e+00, -3.5732e+00, -1.6792e+00,  1.8666e+00]],\n       grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = resnet(batch_Coconut_t)\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:54:10.278796Z",
     "start_time": "2023-08-01T14:54:10.115153Z"
    }
   },
   "id": "7c473bad082352f9"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 1000])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape\n",
    "# batch size为 1\n",
    "# 1000 是因为 imagenet 有 1000 个种类所以做出 1000个推理，理论上可以找到传入的图是什么东西（人）"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:54:37.960510Z",
     "start_time": "2023-08-01T14:54:37.947009Z"
    }
   },
   "id": "274afba17757e40d"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(854)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.argmax()\n",
    "# 输出结果第 854 个最大"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:56:24.030068Z",
     "start_time": "2023-08-01T14:56:24.014194Z"
    }
   },
   "id": "f3a204577c03dbc2"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "with open('imagenet_classes.txt') as f:\n",
    "    labels = [line.strip() for line in f.readlines()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T15:07:59.529394Z",
     "start_time": "2023-08-01T15:07:59.503329Z"
    }
   },
   "id": "c95a3a4cd88c5f80"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "['0, tench',\n '1, goldfish',\n '2, great_white_shark',\n '3, tiger_shark',\n '4, hammerhead',\n '5, electric_ray',\n '6, stingray',\n '7, cock',\n '8, hen',\n '9, ostrich',\n '10, brambling',\n '11, goldfinch',\n '12, house_finch',\n '13, junco',\n '14, indigo_bunting',\n '15, robin',\n '16, bulbul',\n '17, jay',\n '18, magpie',\n '19, chickadee',\n '20, water_ouzel',\n '21, kite',\n '22, bald_eagle',\n '23, vulture',\n '24, great_grey_owl',\n '25, European_fire_salamander',\n '26, common_newt',\n '27, eft',\n '28, spotted_salamander',\n '29, axolotl',\n '30, bullfrog',\n '31, tree_frog',\n '32, tailed_frog',\n '33, loggerhead',\n '34, leatherback_turtle',\n '35, mud_turtle',\n '36, terrapin',\n '37, box_turtle',\n '38, banded_gecko',\n '39, common_iguana',\n '40, American_chameleon',\n '41, whiptail',\n '42, agama',\n '43, frilled_lizard',\n '44, alligator_lizard',\n '45, Gila_monster',\n '46, green_lizard',\n '47, African_chameleon',\n '48, Komodo_dragon',\n '49, African_crocodile',\n '50, American_alligator',\n '51, triceratops',\n '52, thunder_snake',\n '53, ringneck_snake',\n '54, hognose_snake',\n '55, green_snake',\n '56, king_snake',\n '57, garter_snake',\n '58, water_snake',\n '59, vine_snake',\n '60, night_snake',\n '61, boa_constrictor',\n '62, rock_python',\n '63, Indian_cobra',\n '64, green_mamba',\n '65, sea_snake',\n '66, horned_viper',\n '67, diamondback',\n '68, sidewinder',\n '69, trilobite',\n '70, harvestman',\n '71, scorpion',\n '72, black_and_gold_garden_spider',\n '73, barn_spider',\n '74, garden_spider',\n '75, black_widow',\n '76, tarantula',\n '77, wolf_spider',\n '78, tick',\n '79, centipede',\n '80, black_grouse',\n '81, ptarmigan',\n '82, ruffed_grouse',\n '83, prairie_chicken',\n '84, peacock',\n '85, quail',\n '86, partridge',\n '87, African_grey',\n '88, macaw',\n '89, sulphur-crested_cockatoo',\n '90, lorikeet',\n '91, coucal',\n '92, bee_eater',\n '93, hornbill',\n '94, hummingbird',\n '95, jacamar',\n '96, toucan',\n '97, drake',\n '98, red-breasted_merganser',\n '99, goose',\n '100, black_swan',\n '101, tusker',\n '102, echidna',\n '103, platypus',\n '104, wallaby',\n '105, koala',\n '106, wombat',\n '107, jellyfish',\n '108, sea_anemone',\n '109, brain_coral',\n '110, flatworm',\n '111, nematode',\n '112, conch',\n '113, snail',\n '114, slug',\n '115, sea_slug',\n '116, chiton',\n '117, chambered_nautilus',\n '118, Dungeness_crab',\n '119, rock_crab',\n '120, fiddler_crab',\n '121, king_crab',\n '122, American_lobster',\n '123, spiny_lobster',\n '124, crayfish',\n '125, hermit_crab',\n '126, isopod',\n '127, white_stork',\n '128, black_stork',\n '129, spoonbill',\n '130, flamingo',\n '131, little_blue_heron',\n '132, American_egret',\n '133, bittern',\n '134, crane',\n '135, limpkin',\n '136, European_gallinule',\n '137, American_coot',\n '138, bustard',\n '139, ruddy_turnstone',\n '140, red-backed_sandpiper',\n '141, redshank',\n '142, dowitcher',\n '143, oystercatcher',\n '144, pelican',\n '145, king_penguin',\n '146, albatross',\n '147, grey_whale',\n '148, killer_whale',\n '149, dugong',\n '150, sea_lion',\n '151, Chihuahua',\n '152, Japanese_spaniel',\n '153, Maltese_dog',\n '154, Pekinese',\n '155, Shih-Tzu',\n '156, Blenheim_spaniel',\n '157, papillon',\n '158, toy_terrier',\n '159, Rhodesian_ridgeback',\n '160, Afghan_hound',\n '161, basset',\n '162, beagle',\n '163, bloodhound',\n '164, bluetick',\n '165, black-and-tan_coonhound',\n '166, Walker_hound',\n '167, English_foxhound',\n '168, redbone',\n '169, borzoi',\n '170, Irish_wolfhound',\n '171, Italian_greyhound',\n '172, whippet',\n '173, Ibizan_hound',\n '174, Norwegian_elkhound',\n '175, otterhound',\n '176, Saluki',\n '177, Scottish_deerhound',\n '178, Weimaraner',\n '179, Staffordshire_bullterrier',\n '180, American_Staffordshire_terrier',\n '181, Bedlington_terrier',\n '182, Border_terrier',\n '183, Kerry_blue_terrier',\n '184, Irish_terrier',\n '185, Norfolk_terrier',\n '186, Norwich_terrier',\n '187, Yorkshire_terrier',\n '188, wire-haired_fox_terrier',\n '189, Lakeland_terrier',\n '190, Sealyham_terrier',\n '191, Airedale',\n '192, cairn',\n '193, Australian_terrier',\n '194, Dandie_Dinmont',\n '195, Boston_bull',\n '196, miniature_schnauzer',\n '197, giant_schnauzer',\n '198, standard_schnauzer',\n '199, Scotch_terrier',\n '200, Tibetan_terrier',\n '201, silky_terrier',\n '202, soft-coated_wheaten_terrier',\n '203, West_Highland_white_terrier',\n '204, Lhasa',\n '205, flat-coated_retriever',\n '206, curly-coated_retriever',\n '207, golden_retriever',\n '208, Labrador_retriever',\n '209, Chesapeake_Bay_retriever',\n '210, German_short-haired_pointer',\n '211, vizsla',\n '212, English_setter',\n '213, Irish_setter',\n '214, Gordon_setter',\n '215, Brittany_spaniel',\n '216, clumber',\n '217, English_springer',\n '218, Welsh_springer_spaniel',\n '219, cocker_spaniel',\n '220, Sussex_spaniel',\n '221, Irish_water_spaniel',\n '222, kuvasz',\n '223, schipperke',\n '224, groenendael',\n '225, malinois',\n '226, briard',\n '227, kelpie',\n '228, komondor',\n '229, Old_English_sheepdog',\n '230, Shetland_sheepdog',\n '231, collie',\n '232, Border_collie',\n '233, Bouvier_des_Flandres',\n '234, Rottweiler',\n '235, German_shepherd',\n '236, Doberman',\n '237, miniature_pinscher',\n '238, Greater_Swiss_Mountain_dog',\n '239, Bernese_mountain_dog',\n '240, Appenzeller',\n '241, EntleBucher',\n '242, boxer',\n '243, bull_mastiff',\n '244, Tibetan_mastiff',\n '245, French_bulldog',\n '246, Great_Dane',\n '247, Saint_Bernard',\n '248, Eskimo_dog',\n '249, malamute',\n '250, Siberian_husky',\n '251, dalmatian',\n '252, affenpinscher',\n '253, basenji',\n '254, pug',\n '255, Leonberg',\n '256, Newfoundland',\n '257, Great_Pyrenees',\n '258, Samoyed',\n '259, Pomeranian',\n '260, chow',\n '261, keeshond',\n '262, Brabancon_griffon',\n '263, Pembroke',\n '264, Cardigan',\n '265, toy_poodle',\n '266, miniature_poodle',\n '267, standard_poodle',\n '268, Mexican_hairless',\n '269, timber_wolf',\n '270, white_wolf',\n '271, red_wolf',\n '272, coyote',\n '273, dingo',\n '274, dhole',\n '275, African_hunting_dog',\n '276, hyena',\n '277, red_fox',\n '278, kit_fox',\n '279, Arctic_fox',\n '280, grey_fox',\n '281, tabby',\n '282, tiger_cat',\n '283, Persian_cat',\n '284, Siamese_cat',\n '285, Egyptian_cat',\n '286, cougar',\n '287, lynx',\n '288, leopard',\n '289, snow_leopard',\n '290, jaguar',\n '291, lion',\n '292, tiger',\n '293, cheetah',\n '294, brown_bear',\n '295, American_black_bear',\n '296, ice_bear',\n '297, sloth_bear',\n '298, mongoose',\n '299, meerkat',\n '300, tiger_beetle',\n '301, ladybug',\n '302, ground_beetle',\n '303, long-horned_beetle',\n '304, leaf_beetle',\n '305, dung_beetle',\n '306, rhinoceros_beetle',\n '307, weevil',\n '308, fly',\n '309, bee',\n '310, ant',\n '311, grasshopper',\n '312, cricket',\n '313, walking_stick',\n '314, cockroach',\n '315, mantis',\n '316, cicada',\n '317, leafhopper',\n '318, lacewing',\n '319, dragonfly',\n '320, damselfly',\n '321, admiral',\n '322, ringlet',\n '323, monarch',\n '324, cabbage_butterfly',\n '325, sulphur_butterfly',\n '326, lycaenid',\n '327, starfish',\n '328, sea_urchin',\n '329, sea_cucumber',\n '330, wood_rabbit',\n '331, hare',\n '332, Angora',\n '333, hamster',\n '334, porcupine',\n '335, fox_squirrel',\n '336, marmot',\n '337, beaver',\n '338, guinea_pig',\n '339, sorrel',\n '340, zebra',\n '341, hog',\n '342, wild_boar',\n '343, warthog',\n '344, hippopotamus',\n '345, ox',\n '346, water_buffalo',\n '347, bison',\n '348, ram',\n '349, bighorn',\n '350, ibex',\n '351, hartebeest',\n '352, impala',\n '353, gazelle',\n '354, Arabian_camel',\n '355, llama',\n '356, weasel',\n '357, mink',\n '358, polecat',\n '359, black-footed_ferret',\n '360, otter',\n '361, skunk',\n '362, badger',\n '363, armadillo',\n '364, three-toed_sloth',\n '365, orangutan',\n '366, gorilla',\n '367, chimpanzee',\n '368, gibbon',\n '369, siamang',\n '370, guenon',\n '371, patas',\n '372, baboon',\n '373, macaque',\n '374, langur',\n '375, colobus',\n '376, proboscis_monkey',\n '377, marmoset',\n '378, capuchin',\n '379, howler_monkey',\n '380, titi',\n '381, spider_monkey',\n '382, squirrel_monkey',\n '383, Madagascar_cat',\n '384, indri',\n '385, Indian_elephant',\n '386, African_elephant',\n '387, lesser_panda',\n '388, giant_panda',\n '389, barracouta',\n '390, eel',\n '391, coho',\n '392, rock_beauty',\n '393, anemone_fish',\n '394, sturgeon',\n '395, gar',\n '396, lionfish',\n '397, puffer',\n '398, abacus',\n '399, abaya',\n '400, academic_gown',\n '401, accordion',\n '402, acoustic_guitar',\n '403, aircraft_carrier',\n '404, airliner',\n '405, airship',\n '406, altar',\n '407, ambulance',\n '408, amphibian',\n '409, analog_clock',\n '410, apiary',\n '411, apron',\n '412, ashcan',\n '413, assault_rifle',\n '414, backpack',\n '415, bakery',\n '416, balance_beam',\n '417, balloon',\n '418, ballpoint',\n '419, Band_Aid',\n '420, banjo',\n '421, bannister',\n '422, barbell',\n '423, barber_chair',\n '424, barbershop',\n '425, barn',\n '426, barometer',\n '427, barrel',\n '428, barrow',\n '429, baseball',\n '430, basketball',\n '431, bassinet',\n '432, bassoon',\n '433, bathing_cap',\n '434, bath_towel',\n '435, bathtub',\n '436, beach_wagon',\n '437, beacon',\n '438, beaker',\n '439, bearskin',\n '440, beer_bottle',\n '441, beer_glass',\n '442, bell_cote',\n '443, bib',\n '444, bicycle-built-for-two',\n '445, bikini',\n '446, binder',\n '447, binoculars',\n '448, birdhouse',\n '449, boathouse',\n '450, bobsled',\n '451, bolo_tie',\n '452, bonnet',\n '453, bookcase',\n '454, bookshop',\n '455, bottlecap',\n '456, bow',\n '457, bow_tie',\n '458, brass',\n '459, brassiere',\n '460, breakwater',\n '461, breastplate',\n '462, broom',\n '463, bucket',\n '464, buckle',\n '465, bulletproof_vest',\n '466, bullet_train',\n '467, butcher_shop',\n '468, cab',\n '469, caldron',\n '470, candle',\n '471, cannon',\n '472, canoe',\n '473, can_opener',\n '474, cardigan',\n '475, car_mirror',\n '476, carousel',\n \"477, carpenter's_kit\",\n '478, carton',\n '479, car_wheel',\n '480, cash_machine',\n '481, cassette',\n '482, cassette_player',\n '483, castle',\n '484, catamaran',\n '485, CD_player',\n '486, cello',\n '487, cellular_telephone',\n '488, chain',\n '489, chainlink_fence',\n '490, chain_mail',\n '491, chain_saw',\n '492, chest',\n '493, chiffonier',\n '494, chime',\n '495, china_cabinet',\n '496, Christmas_stocking',\n '497, church',\n '498, cinema',\n '499, cleaver',\n '500, cliff_dwelling',\n '501, cloak',\n '502, clog',\n '503, cocktail_shaker',\n '504, coffee_mug',\n '505, coffeepot',\n '506, coil',\n '507, combination_lock',\n '508, computer_keyboard',\n '509, confectionery',\n '510, container_ship',\n '511, convertible',\n '512, corkscrew',\n '513, cornet',\n '514, cowboy_boot',\n '515, cowboy_hat',\n '516, cradle',\n '517, crane',\n '518, crash_helmet',\n '519, crate',\n '520, crib',\n '521, Crock_Pot',\n '522, croquet_ball',\n '523, crutch',\n '524, cuirass',\n '525, dam',\n '526, desk',\n '527, desktop_computer',\n '528, dial_telephone',\n '529, diaper',\n '530, digital_clock',\n '531, digital_watch',\n '532, dining_table',\n '533, dishrag',\n '534, dishwasher',\n '535, disk_brake',\n '536, dock',\n '537, dogsled',\n '538, dome',\n '539, doormat',\n '540, drilling_platform',\n '541, drum',\n '542, drumstick',\n '543, dumbbell',\n '544, Dutch_oven',\n '545, electric_fan',\n '546, electric_guitar',\n '547, electric_locomotive',\n '548, entertainment_center',\n '549, envelope',\n '550, espresso_maker',\n '551, face_powder',\n '552, feather_boa',\n '553, file',\n '554, fireboat',\n '555, fire_engine',\n '556, fire_screen',\n '557, flagpole',\n '558, flute',\n '559, folding_chair',\n '560, football_helmet',\n '561, forklift',\n '562, fountain',\n '563, fountain_pen',\n '564, four-poster',\n '565, freight_car',\n '566, French_horn',\n '567, frying_pan',\n '568, fur_coat',\n '569, garbage_truck',\n '570, gasmask',\n '571, gas_pump',\n '572, goblet',\n '573, go-kart',\n '574, golf_ball',\n '575, golfcart',\n '576, gondola',\n '577, gong',\n '578, gown',\n '579, grand_piano',\n '580, greenhouse',\n '581, grille',\n '582, grocery_store',\n '583, guillotine',\n '584, hair_slide',\n '585, hair_spray',\n '586, half_track',\n '587, hammer',\n '588, hamper',\n '589, hand_blower',\n '590, hand-held_computer',\n '591, handkerchief',\n '592, hard_disc',\n '593, harmonica',\n '594, harp',\n '595, harvester',\n '596, hatchet',\n '597, holster',\n '598, home_theater',\n '599, honeycomb',\n '600, hook',\n '601, hoopskirt',\n '602, horizontal_bar',\n '603, horse_cart',\n '604, hourglass',\n '605, iPod',\n '606, iron',\n \"607, jack-o'-lantern\",\n '608, jean',\n '609, jeep',\n '610, jersey',\n '611, jigsaw_puzzle',\n '612, jinrikisha',\n '613, joystick',\n '614, kimono',\n '615, knee_pad',\n '616, knot',\n '617, lab_coat',\n '618, ladle',\n '619, lampshade',\n '620, laptop',\n '621, lawn_mower',\n '622, lens_cap',\n '623, letter_opener',\n '624, library',\n '625, lifeboat',\n '626, lighter',\n '627, limousine',\n '628, liner',\n '629, lipstick',\n '630, Loafer',\n '631, lotion',\n '632, loudspeaker',\n '633, loupe',\n '634, lumbermill',\n '635, magnetic_compass',\n '636, mailbag',\n '637, mailbox',\n '638, maillot',\n '639, maillot',\n '640, manhole_cover',\n '641, maraca',\n '642, marimba',\n '643, mask',\n '644, matchstick',\n '645, maypole',\n '646, maze',\n '647, measuring_cup',\n '648, medicine_chest',\n '649, megalith',\n '650, microphone',\n '651, microwave',\n '652, military_uniform',\n '653, milk_can',\n '654, minibus',\n '655, miniskirt',\n '656, minivan',\n '657, missile',\n '658, mitten',\n '659, mixing_bowl',\n '660, mobile_home',\n '661, Model_T',\n '662, modem',\n '663, monastery',\n '664, monitor',\n '665, moped',\n '666, mortar',\n '667, mortarboard',\n '668, mosque',\n '669, mosquito_net',\n '670, motor_scooter',\n '671, mountain_bike',\n '672, mountain_tent',\n '673, mouse',\n '674, mousetrap',\n '675, moving_van',\n '676, muzzle',\n '677, nail',\n '678, neck_brace',\n '679, necklace',\n '680, nipple',\n '681, notebook',\n '682, obelisk',\n '683, oboe',\n '684, ocarina',\n '685, odometer',\n '686, oil_filter',\n '687, organ',\n '688, oscilloscope',\n '689, overskirt',\n '690, oxcart',\n '691, oxygen_mask',\n '692, packet',\n '693, paddle',\n '694, paddlewheel',\n '695, padlock',\n '696, paintbrush',\n '697, pajama',\n '698, palace',\n '699, panpipe',\n '700, paper_towel',\n '701, parachute',\n '702, parallel_bars',\n '703, park_bench',\n '704, parking_meter',\n '705, passenger_car',\n '706, patio',\n '707, pay-phone',\n '708, pedestal',\n '709, pencil_box',\n '710, pencil_sharpener',\n '711, perfume',\n '712, Petri_dish',\n '713, photocopier',\n '714, pick',\n '715, pickelhaube',\n '716, picket_fence',\n '717, pickup',\n '718, pier',\n '719, piggy_bank',\n '720, pill_bottle',\n '721, pillow',\n '722, ping-pong_ball',\n '723, pinwheel',\n '724, pirate',\n '725, pitcher',\n '726, plane',\n '727, planetarium',\n '728, plastic_bag',\n '729, plate_rack',\n '730, plow',\n '731, plunger',\n '732, Polaroid_camera',\n '733, pole',\n '734, police_van',\n '735, poncho',\n '736, pool_table',\n '737, pop_bottle',\n '738, pot',\n \"739, potter's_wheel\",\n '740, power_drill',\n '741, prayer_rug',\n '742, printer',\n '743, prison',\n '744, projectile',\n '745, projector',\n '746, puck',\n '747, punching_bag',\n '748, purse',\n '749, quill',\n '750, quilt',\n '751, racer',\n '752, racket',\n '753, radiator',\n '754, radio',\n '755, radio_telescope',\n '756, rain_barrel',\n '757, recreational_vehicle',\n '758, reel',\n '759, reflex_camera',\n '760, refrigerator',\n '761, remote_control',\n '762, restaurant',\n '763, revolver',\n '764, rifle',\n '765, rocking_chair',\n '766, rotisserie',\n '767, rubber_eraser',\n '768, rugby_ball',\n '769, rule',\n '770, running_shoe',\n '771, safe',\n '772, safety_pin',\n '773, saltshaker',\n '774, sandal',\n '775, sarong',\n '776, sax',\n '777, scabbard',\n '778, scale',\n '779, school_bus',\n '780, schooner',\n '781, scoreboard',\n '782, screen',\n '783, screw',\n '784, screwdriver',\n '785, seat_belt',\n '786, sewing_machine',\n '787, shield',\n '788, shoe_shop',\n '789, shoji',\n '790, shopping_basket',\n '791, shopping_cart',\n '792, shovel',\n '793, shower_cap',\n '794, shower_curtain',\n '795, ski',\n '796, ski_mask',\n '797, sleeping_bag',\n '798, slide_rule',\n '799, sliding_door',\n '800, slot',\n '801, snorkel',\n '802, snowmobile',\n '803, snowplow',\n '804, soap_dispenser',\n '805, soccer_ball',\n '806, sock',\n '807, solar_dish',\n '808, sombrero',\n '809, soup_bowl',\n '810, space_bar',\n '811, space_heater',\n '812, space_shuttle',\n '813, spatula',\n '814, speedboat',\n '815, spider_web',\n '816, spindle',\n '817, sports_car',\n '818, spotlight',\n '819, stage',\n '820, steam_locomotive',\n '821, steel_arch_bridge',\n '822, steel_drum',\n '823, stethoscope',\n '824, stole',\n '825, stone_wall',\n '826, stopwatch',\n '827, stove',\n '828, strainer',\n '829, streetcar',\n '830, stretcher',\n '831, studio_couch',\n '832, stupa',\n '833, submarine',\n '834, suit',\n '835, sundial',\n '836, sunglass',\n '837, sunglasses',\n '838, sunscreen',\n '839, suspension_bridge',\n '840, swab',\n '841, sweatshirt',\n '842, swimming_trunks',\n '843, swing',\n '844, switch',\n '845, syringe',\n '846, table_lamp',\n '847, tank',\n '848, tape_player',\n '849, teapot',\n '850, teddy',\n '851, television',\n '852, tennis_ball',\n '853, thatch',\n '854, theater_curtain',\n '855, thimble',\n '856, thresher',\n '857, throne',\n '858, tile_roof',\n '859, toaster',\n '860, tobacco_shop',\n '861, toilet_seat',\n '862, torch',\n '863, totem_pole',\n '864, tow_truck',\n '865, toyshop',\n '866, tractor',\n '867, trailer_truck',\n '868, tray',\n '869, trench_coat',\n '870, tricycle',\n '871, trimaran',\n '872, tripod',\n '873, triumphal_arch',\n '874, trolleybus',\n '875, trombone',\n '876, tub',\n '877, turnstile',\n '878, typewriter_keyboard',\n '879, umbrella',\n '880, unicycle',\n '881, upright',\n '882, vacuum',\n '883, vase',\n '884, vault',\n '885, velvet',\n '886, vending_machine',\n '887, vestment',\n '888, viaduct',\n '889, violin',\n '890, volleyball',\n '891, waffle_iron',\n '892, wall_clock',\n '893, wallet',\n '894, wardrobe',\n '895, warplane',\n '896, washbasin',\n '897, washer',\n '898, water_bottle',\n '899, water_jug',\n '900, water_tower',\n '901, whiskey_jug',\n '902, whistle',\n '903, wig',\n '904, window_screen',\n '905, window_shade',\n '906, Windsor_tie',\n '907, wine_bottle',\n '908, wing',\n '909, wok',\n '910, wooden_spoon',\n '911, wool',\n '912, worm_fence',\n '913, wreck',\n '914, yawl',\n '915, yurt',\n '916, web_site',\n '917, comic_book',\n '918, crossword_puzzle',\n '919, street_sign',\n '920, traffic_light',\n '921, book_jacket',\n '922, menu',\n '923, plate',\n '924, guacamole',\n '925, consomme',\n '926, hot_pot',\n '927, trifle',\n '928, ice_cream',\n '929, ice_lolly',\n '930, French_loaf',\n '931, bagel',\n '932, pretzel',\n '933, cheeseburger',\n '934, hotdog',\n '935, mashed_potato',\n '936, head_cabbage',\n '937, broccoli',\n '938, cauliflower',\n '939, zucchini',\n '940, spaghetti_squash',\n '941, acorn_squash',\n '942, butternut_squash',\n '943, cucumber',\n '944, artichoke',\n '945, bell_pepper',\n '946, cardoon',\n '947, mushroom',\n '948, Granny_Smith',\n '949, strawberry',\n '950, orange',\n '951, lemon',\n '952, fig',\n '953, pineapple',\n '954, banana',\n '955, jackfruit',\n '956, custard_apple',\n '957, pomegranate',\n '958, hay',\n '959, carbonara',\n '960, chocolate_sauce',\n '961, dough',\n '962, meat_loaf',\n '963, pizza',\n '964, potpie',\n '965, burrito',\n '966, red_wine',\n '967, espresso',\n '968, cup',\n '969, eggnog',\n '970, alp',\n '971, bubble',\n '972, cliff',\n '973, coral_reef',\n '974, geyser',\n '975, lakeside',\n '976, promontory',\n '977, sandbar',\n '978, seashore',\n '979, valley',\n '980, volcano',\n '981, ballplayer',\n '982, groom',\n '983, scuba_diver',\n '984, rapeseed',\n '985, daisy',\n \"986, yellow_lady's_slipper\",\n '987, corn',\n '988, acorn',\n '989, hip',\n '990, buckeye',\n '991, coral_fungus',\n '992, agaric',\n '993, gyromitra',\n '994, stinkhorn',\n '995, earthstar',\n '996, hen-of-the-woods',\n '997, bolete',\n '998, ear',\n '999, toilet_tissue']"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T15:08:01.147394Z",
     "start_time": "2023-08-01T15:08:01.122671Z"
    }
   },
   "id": "dcad4afd42d242de"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "'854, theater_curtain'"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[854]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T15:08:03.360099Z",
     "start_time": "2023-08-01T15:08:03.331855Z"
    }
   },
   "id": "fadc617e67f6b8a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84295bc257fcae9d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
